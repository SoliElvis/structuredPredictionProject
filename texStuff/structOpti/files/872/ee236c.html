<html><head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="lvdb.css" type="text/css">
<title>ECE236C - Optimization Methods for Large-Scale Systems (Spring 2019)</title>
<style type="text/css"></style><style>@media print {#ghostery-purple-box {display:none !important}}</style></head>
<body data-gr-c-s-loaded="true">
<div id="layout-content">
<div id="toptitle">
<h1>ECE236C - Optimization Methods for Large-Scale Systems (Spring 2019)</h1>
<div id="subtitle"><a href="http://www.seas.ucla.edu/%7Evandenbe/index.html">Prof. L. Vandenberghe</a>,  UCLA</div>
</div>
<h2>Lecture notes  (Spring 2016)</h2>
<ol>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/gradient.pdf">Gradient method</a></p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/qnewton.pdf">Quasi-Newton methods</a></p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/cg.pdf">Conjugate gradient method</a> </p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/subgradients.pdf">Subgradients</a></p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/sgmethod.pdf">Subgradient method</a></p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/proxgrad.pdf">Proximal gradient method</a></p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/conj.pdf">Conjugate functions</a></p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/proxop.pdf">The proximal mapping</a></p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/fgrad.pdf">Accelerated proximal gradient methods</a> </p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/ppm.pdf">Proximal point method</a></p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/dualdecomp.pdf">Dual decomposition</a></p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/dualproxgrad.pdf">Dual proximal gradient method</a> </p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/dr.pdf">Douglas-Rachford splitting and ADMM</a></p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/cp.pdf">Primal-dual proximal methods</a> </p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/conic.pdf">Conic optimization</a></p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/barriers.pdf">Barrier functions</a></p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/pf.pdf">Path-following methods</a></p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/symmetric.pdf">Symmetric cones</a></p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/pd.pdf">Primal-dual interior-point methods</a>  </p>
</li>
</ol>
<p><b>Additional lectures</b> (from previous editions of the course) </p>
<ul>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/fista.pdf">Fast proximal gradient methods (FISTA)</a></p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/smoothing.pdf">Smoothing</a></p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/proxop2.pdf">Proximal mapping via network optimization</a> </p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/localization.pdf">Cutting-plane methods</a></p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/accpm.pdf">Analytic center cutting-plane method</a></p>
</li>
<li><p><a href="http://www.seas.ucla.edu/%7Evandenbe/236C/lectures/ellipsoid.pdf">Ellipsoid method</a></p>
</li>
</ul>
<h2>Homework and project</h2>
<p>Homework solutions are posted on the 
<a href="https://ccle.ucla.edu/course/view/19S-ECENGR236C-1">CCLE course website</a>.  </p>
<h2>Course information </h2>
<p><b>Description.</b>
The course continues 
<a href="http://www.seas.ucla.edu/%7Evandenbe/ee236b/ee236b.html">ECE236B</a>
and covers several advanced and current topics in optimization,  with an 
emphasis on large-scale algorithms for convex optimization.
This includes first-order methods for large-scale optimization 
(gradient and subgradient method, conjugate gradient method, proximal 
gradient method, accelerated gradient methods),
decomposition and splitting methods 
(dual decomposition, augmented Lagrangian method, alternating direction 
method of multipliers, monotone operators and operator splitting),
and (possibly) interior-point algorithms for conic optimization.</p>
<p><b>Lecture notes.</b>
The lecture notes will be posted on this website.  Many of the topics
are covered in the following books and in the
course <a href="http://www.stanford.edu/class/ee364b/">EE364b (Convex Optimization II)</a> at Stanford University.</p>
<ul>
<li><p>A. Beck, 
<a href="https://doi.org/10.1137/1.9781611974997"><i>First-Order Methods in Optimization</i></a>, SIAM.</p>
</li>
<li><p>D. Bertsekas, 
<i>Convex Optimization Algorithms</i>, Athena Scientific.</p>
</li>
<li><p>D. Bertsekas and J. Tsitsiklis, 
<i>Parallel and Distributed Computation</i>,
Athena Scientific.</p>
</li>
<li><p>Yu. Nesterov, 
<a href="https://doi.org/10.1007/978-3-319-91578-4"><i>Lectures on Convex Optimization</i></a>, Springer.</p>
</li>
<li><p>J. Nocedal and S. Wright, 
<a href="http://dx.doi.org/10.1007/978-0-387-40065-5"><i>Numerical Optimization</i></a>, Springer.</p>
</li>
<li><p>B. T. Polyak, <i>Introduction to Optimization</i>, Optimization Software.</p>
</li>
</ul>
<p><b>Course requirements</b>.  Weekly homework assignments and a project.</p>
<p><b>Grading</b>. 
Approximate weights in the final grade: homework 30%, project 70%.</p>
</div>


<iframe scrolling="no" style="background-color: transparent; border: 0px; display: none;" frameborder="0"></iframe><div id="GOOGLE_INPUT_CHEXT_FLAG" style="display: none;" input="" input_stat="{&quot;tlang&quot;:true,&quot;tsbc&quot;:true,&quot;pun&quot;:true,&quot;mk&quot;:true,&quot;ss&quot;:true}"></div></body></html>