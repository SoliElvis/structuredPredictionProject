diff a/expcode/dataprep/batch_data_prep.py b/expcode/dataprep/batch_data_prep.py	(rejected hunks)
@@ -5,91 +5,92 @@ import os
 import argparse
 import wget
 import ssl
-import PIL
-from PIL import Image
-from PIL import ImageOps
+import pil
+from pil import image
+from pil import imageops
 import urllib
 import timeit
-from io import BytesIO
+from io import bytesio
 import requests
 import wget
 import time
 
-from typing import List
-from IPython.core import debugger
-debug = debugger.Pdb().set_trace
+from typing import list
+from ipython.core import debugger
+debug = debugger.pdb().set_trace
 import pathlib
 from os import listdir
 from os.path import isfile, join, walk
 from itertools import islice
 
-save_dir = "./FEC_dataset"
+save_dir = "./fec_dataset"
 process_dir = "./process_fec"
 train_csv = "faceexp-comparison-data-train-public.csv"
 test_csv = "faceexp-comparison-data-test-public.csv"
 tt= ("train", "test")
 lineskip=18
-csvRange=(0,4000,lineskip)
+csvrange=(0,4000,lineskip)
 
 #utilities
 def tt_join_paths(prefixes):
   r = [os.path.join(p,t) for p in prefixes for t in tt]
   return r
 def parse_arguments():
-  parser = argparse.ArgumentParser()
-  parser.add_argument("--save_dir", type=str, default="./FEC_dataset")
+  parser = argparse.argumentparser()
+  parser.add_argument("--save_dir", type=str, default="./fec_dataset")
   parser.add_argument("--data_path", type=str,
-                      default="./FEC_dataset/faceexp-comparison-data-train-public.csv",
-                      help="Path to  the data file")
+                      default="./fec_dataset/faceexp-comparison-data-train-public.csv",
+                      help="path to  the data file")
   parser.add_argument("--dim", type=int, default=32,
-                      help="The desired dimension for the images")
+                      help="the desired dimension for the images")
   parser.add_argument("--images_path", type=str,
                       default="./face_images",
-                      help="Path to directory to store images")
+                      help="path to directory to store images")
   args, unkown = parser.parse_known_args()
   return args
 
-def createFolder(directory_list : List[str]):
+def createfolder(directory_list : list[str]):
   print(directory_list)
   for directory in directory_list:
     try:
       if not os.path.exists(directory):
         os.makedirs(directory)
-    except OSError:
-      print ('Error: Creating directory. ' +  directory)
+    except oserror:
+      print ('error: creating directory. ' +  directory)
 
   return directory_list
 
 
-class ImageDataPrep:
+class imagedataprep:
   def __init__(self,save_dir,process_dir,dim=32):
     self.save_dir = save_dir
-    self.imagesDir = os.path.join(process_dir, "images")
-    self.dataDir = os.path.join(process_dir, "data")
+    self.imagesdir = os.path.join(process_dir, "images")
+    self.datadir = os.path.join(process_dir, "data")
 
-    self.dataSets = [os.path.join(self.process_dir, f) for f in [train_csv,test_csv]]
-    self.dataPathDict = {"train" : self.dataSets[0],
-                         "test"  : self.dataSets[1]}
+    self.csvdatasets = [os.path.join(self.process_dir, f) for f in [train_csv,test_csv]]
+    self.csvdatapathdict = {"train" : self.csvdatasets[0],
+                            "test"  : self.csvdatasets[1]}
     self._prep_file_system()
     self.dim = dim
 
   def _prep_file_system(self):
-    dirsToCreate = tt_join_paths([self.imagesDir,self.dataDir])
-    createFolder(dirsToCreate)
-    return dirsToCreate
+    dirstocreate = tt_join_paths([self.imagesdir,self.datadir])
+    createfolder(dirstocreate)
+    return dirstocreate
 
 
-class ImageDataPrepFEC(ImageDataPrep):
-  def __init__(self,save_dir="./FEC_dataset",process_dir="./process_fec/"):
+
+class imagedataprepfec(imagedataprep):
+  def __init__(self,save_dir="./fec_dataset",process_dir="./process_fec/"):
     self.save_dir = save_dir
     self.process_dir = process_dir
-    self.local_state_dict = None
-    ImageDataPrep.__init__(self,self.save_dir,self.process_dir)
+    self.local_state_dict = none
+    imagedataprep.__init__(self,self.save_dir,self.process_dir)
 
-  def batch_download_images(self,spamreader=True,skip=4000,stopLine=5000):
-    urlSlots = [0,5,10]
+  def batch_download_images(self,spamreader=true,skip=4000,stopline=5000):
+    urlslots = [0,5,10]
     ssl._create_default_https_context = ssl._create_unverified_context
-    for testOrTrainStr, path in self.dataPathDict.items():
+    for testortrainstr, path in self.csvdatapathdict.items():
       with open(path) as csv_file:
         csv_reader = csv.reader(csv_file, delimiter=',')
         it = enumerate(csv_reader)
@@ -103,9 +104,9 @@ class ImageDataPrepFEC(ImageDataPrep):
 
         for id, row in it:
           print(id)
-          if id >= stopLine:
+          if id >= stopline:
             break
-          for slot in urlSlots:
+          for slot in urlslots:
             url = row[slot]
             response = requests.get(url)
 
@@ -113,24 +114,24 @@ class ImageDataPrepFEC(ImageDataPrep):
               print(" not 200")
               break
 
-            path = os.path.join(self.imagesDir,testOrTrainStr, str(id) + "-" + str(slot) + ".jpg")
-            if not pathlib.Path(path).is_file():
+            path = os.path.join(self.imagesdir,testortrainstr, str(id) + "-" + str(slot) + ".jpg")
+            if not pathlib.path(path).is_file():
               try:
                 wget.download(url, out=path)
               except :
                 print(path)
             print(path)
 
-  def process_data(self,spamreader=True,skip=4000,stopLine=5000):
-    urlSlots = [0,5,10]
+  def process_data(self,spamreader=true,skip=4000,stopline=5000):
+    urlslots = [0,5,10]
     tt = ("train", "test")
-    for testOrTrainStr in tt:
-      dataPath = self.dataPathDict[testOrTrainStr]
+    for testortrainstr in tt:
+      datapath = self.csvdatapathdict[testortrainstr]
       try:
-        p = os.path.join(self.process_dir,testOrTrainStr,"image_processed.npy")
+        p = os.path.join(self.process_dir,testortrainstr,"image_processed.npy")
         print(p)
         f = open(p, "w+")
-        with open(dataPath) as csv_file:
+        with open(datapath) as csv_file:
           csv_reader = csv.reader(csv_file, delimiter=',')
           it = enumerate(csv_reader)
           if (spamreader):
@@ -141,38 +142,38 @@ class ImageDataPrepFEC(ImageDataPrep):
                 break
 
           for id, row in it:
-            for slot in urlSlots:
+            for slot in urlslots:
               print(id)
-              if (spamreader and id >= stopLine):
+              if (spamreader and id >= stopline):
                 break
 
-              imagePath = os.path.join(self.imagesDir,testOrTrainStr, str(id) + "-" + str(slot) + ".jpg")
+              imagepath = os.path.join(self.imagesdir,testortrainstr, str(id) + "-" + str(slot) + ".jpg")
               try:
                 if not os.path.isfile(image_path):
                   continue
-                im = Image.open(BytesIO(imagePath))
+                im = image.open(bytesio(imagepath))
                 to_save = self.image_processing(im,id,row)
                 np.save(f.name, to_save)
 
-              except ValueError as e:
+              except valueerror as e:
                 print("=".join("value error",str(id),str(row)))
-              except Exception as e:
-                print("=".join("Maybe Image not a thruple : ", str(id), str(row)))
+              except exception as e:
+                print("=".join("maybe image not a thruple : ", str(id), str(row)))
                 raise e
 
-      except FileExistsError:
+      except fileexistserror:
         print("exists")
-      except Exception as e:
+      except exception as e:
         print("skipppp")
         print(e)
         pass
 
   def _check_local_images(self):
-		mypath = "./process_fec/data"
-		f = []
-		for (dirpath, dirnames, filenames) in walk(mypath):
-			f.extend(filenames)
-		print(filenames)
+    mypath = os.path.join(self.process_dir, data)
+    f = []
+    for (dirpath, dirnames, filenames) in walk(mypath):
+      f.extend(filenames)
+    print(filenames)
 
   def _image_processing(self,im,id,row):
     w, h = im.size
@@ -181,23 +182,23 @@ class ImageDataPrepFEC(ImageDataPrep):
     area = (int(left), int(up), int(right), int(down))
     crop = im.crop(area)
     # resize the image to the right proportion
-    Crop = np.asarray(ImageOps.fit(crop, (self.dim,self.dim), Image.ANTIALIAS), dtype=np.float32)
+    crop = np.asarray(imageops.fit(crop, (self.dim,self.dim), image.antialias), dtype=np.float32)
     # append the image to image tuple
     im_tup.append(crop)
     # if the image tuple does  not contain three images skip
     if not len(im_tup) == 3:
-      raise Exception("Not a thruple")
+      raise exception("not a thruple")
 
     # extract features and label
     try:
       features = np.stack(im_tup).ravel()
-    except ValueError:
-      raise ValueError
+    except valueerror:
+      raise valueerror
 
     label = np.asarray([row[17 + i * 2] for i in range(6)], dtype=np.float32)
-    if row[15] == "ONE_CLASS_TRIPLET":
+    if row[15] == "one_class_triplet":
       label = np.concatenate(([1.], label)).astype("float32")
-    elif row[15] == "TWO_CLASS_TRIPLET":
+    elif row[15] == "two_class_triplet":
       label = np.concatenate(([2.], label)).astype("float32")
     else:
       label = np.concatenate(([3], label)).astype("float32")
@@ -207,10 +208,10 @@ class ImageDataPrepFEC(ImageDataPrep):
     to_save = np.concatenate((to_save, im_tup))
     return to_save
 
-  def _troubleshoot(self,spamreader=False):
-    urlSlots = [0,5,10]
+  def _troubleshoot(self,spamreader=false):
+    urlslots = [0,5,10]
     ssl._create_default_https_context = ssl._create_unverified_context
-    csv_file = open(self.dataSets[0])
+    csv_file = open(self.csvdatasets[0])
     if spamreader:
       spamreader = csv.reader(csv_file, delimiter=',')
       for row in spamreader:
@@ -222,14 +223,11 @@ class ImageDataPrepFEC(ImageDataPrep):
 
 def main():
   start = time.time()
-  test = ImageDataPrepFEC()
+  test = imagedataprepfec()
   # test.batch_download_images()
   # test.process_data()
   return test
-  print("Elapsed time", time.time() - start)
+  print("elapsed time", time.time() - start)
 
 if __name__ == "__main__":
   main()
-
-
-
